{
  "project": {
    "name": "medical-asr-whisper",
    "output_dir": "./output/medical-asr",
    "seed": 42
  },
  "data": {
    "source": "csv",
    "path": "./data/medical_transcriptions.csv",
    "format": "audio",
    "test_split": 0.1,
    "audio_column": "audio_path",
    "transcription_column": "transcription"
  },
  "model": {
    "name": "openai/whisper-small",
    "task": "asr",
    "quantization": "none",
    "max_seq_length": 448,
    "dtype": "float16"
  },
  "lora": {
    "r": 16,
    "alpha": 32,
    "dropout": 0.05,
    "target_modules": ["q_proj", "v_proj"],
    "task_type": "SEQ_2_SEQ_LM"
  },
  "training": {
    "epochs": 3,
    "batch_size": 8,
    "gradient_accumulation_steps": 2,
    "learning_rate": 1e-5,
    "fp16": true,
    "gradient_checkpointing": true
  },
  "logging": {
    "log_steps": 10,
    "save_steps": 500,
    "eval_steps": 500,
    "save_total_limit": 2
  }
}
