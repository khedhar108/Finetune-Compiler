{
  "project": {
    "name": "tiny-model-finetune",
    "output_dir": "./output",
    "seed": 42
  },
  "data": {
    "source": "csv",
    "path": "./data/train.csv",
    "format": "alpaca",
    "test_split": 0.1,
    "max_samples": 5000
  },
  "model": {
    "name": "unsloth/Llama-3.2-1B",
    "quantization": "4bit",
    "max_seq_length": 1024,
    "dtype": "auto"
  },
  "lora": {
    "r": 8,
    "alpha": 16,
    "dropout": 0.05,
    "target_modules": ["q_proj", "v_proj"]
  },
  "training": {
    "epochs": 1,
    "batch_size": 2,
    "gradient_accumulation_steps": 8,
    "learning_rate": 2e-4,
    "fp16": true,
    "gradient_checkpointing": true
  },
  "logging": {
    "log_steps": 5,
    "save_steps": 50,
    "save_total_limit": 2
  }
}
